{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aa74260",
   "metadata": {},
   "source": [
    "# Building an AWS<sup>®</sup> ML Pipeline with SageWorks (Classification)\n",
    "\n",
    "<div style=\"padding: 20px\">\n",
    "<img width=\"1000\" alt=\"sageworks_pipeline\" src=\"https://github.com/SuperCowPowers/sageworks/assets/4806709/47cc5739-971c-48c3-9ef6-fd8370e3ec57\"></div>\n",
    "\n",
    "This notebook uses the SageWorks Science Workbench to quickly build an AWS® Machine Learning Pipeline with the AQSolDB public dataset. This dataset aggregates aqueous solubility data for a large set of compounds.\n",
    "\n",
    "We're going to set up a full AWS Machine Learning Pipeline from start to finish. Since the SageWorks Classes encapsulate, organize, and manage sets of AWS® Services, setting up our ML pipeline will be straight forward.\n",
    "\n",
    "SageWorks also provides visibility into AWS services for every step of the process so we know exactly what we've got and how to use it.\n",
    "<br><br>\n",
    "\n",
    "## Data\n",
    "Wine Dataset: A classic dataset used in pattern recognition, machine learning, and data mining, the Wine dataset comprises 178 wine samples sourced from three different cultivars in Italy. The dataset features 13 physico-chemical attributes for each wine sample, providing a multi-dimensional feature space ideal for classification tasks. The aim is to correctly classify the wine samples into one of the three cultivars based on these chemical constituents. This dataset is widely employed for testing and benchmarking classification algorithms and is notable for its well-balanced distribution among classes. It serves as a straightforward, real-world example for classification tasks in machine learning.\n",
    "\n",
    "**Main Reference:**\n",
    "Forster, P. (1991). Machine Learning of Natural Language and Ontology (Technical Report DAI-TR-261). Department of Artificial Intelligence, University of Edinburgh.\n",
    "\n",
    "**Data Downloaded from UCI:**\n",
    "https://archive.ics.uci.edu/ml/datasets/Wine\n",
    "\n",
    "\n",
    "## SageWorks\n",
    "SageWorks is a medium granularity framework that manages and aggregates AWS® Services into classes and concepts. When you use SageWorks you think about DataSources, FeatureSets, Models, and Endpoints. Underneath the hood those classes handle all the details around updating and\n",
    "\n",
    "## Notebook\n",
    "This notebook uses the SageWorks Science Workbench to quickly build an AWS® Machine Learning Pipeline.\n",
    "\n",
    "We're going to set up a full AWS Machine Learning Pipeline from start to finish. Since the SageWorks Classes encapsulate, organize, and manage sets of AWS® Services, setting up our ML pipeline will be straight forward.\n",
    "\n",
    "SageWorks also provides visibility into AWS services for every step of the process so we know exactly what we've got and how to use it.\n",
    "<br><br>\n",
    "\n",
    "® Amazon Web Services, AWS, the Powered by AWS logo, are trademarks of Amazon.com, Inc. or its affiliates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae1c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay first we get our data into SageWorks as a DataSource\n",
    "from sageworks.transforms.data_loaders.light.csv_to_data_source import CSVToDataSource"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293eca72",
   "metadata": {},
   "source": [
    "# SageWorks help is actually helpful\n",
    "Every class in SageWorks is self documenting, just use `help(ClassName)` and you'll get help like this...\n",
    "```\n",
    "help(CSVToDataSource)\n",
    "Help on class CSVToDataSource in module sageworks.transforms.data_loaders.light.csv_to_data_source:\n",
    "\n",
    "class CSVToDataSource(sageworks.transforms.transform.Transform)\n",
    " |  CSVToDataSource(csv_file_path: str, data_uuid: str)\n",
    " |  \n",
    " |  CSVToDataSource: Class to move local CSV Files into a SageWorks DataSource\n",
    " |  \n",
    " |  Common Usage:\n",
    " |      csv_to_data = CSVToDataSource(csv_file_path, data_uuid)\n",
    " |      csv_to_data.set_output_tags([\"abalone\", \"csv\", \"whatever\"])\n",
    " |      csv_to_data.transform()\n",
    " |  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97243583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: If you want to use data from S3 just use 'S3ToDataSource'\n",
    "csv_path = '/Users/briford/data/sageworks/wine_classification.csv'\n",
    "to_data_source = CSVToDataSource(csv_path, 'wine_data')\n",
    "to_data_source.set_output_tags(['wine', 'classification'])\n",
    "to_data_source.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31affdf1",
   "metadata": {},
   "source": [
    "<div style=\"float: right; padding: 20px\"><img src=\"images/aws_dashboard_aqsol.png\" width=600px\"></div>\n",
    "\n",
    "# So what just happened?\n",
    "Okay, so it was just a few lines of code but SageWorks did the following for you:\n",
    "   \n",
    "- Transformed the CSV to a **Parquet** formatted dataset and stored it in AWS S3\n",
    "- Created an AWS Data Catalog database/table with the columns names/types\n",
    "- Athena Queries can now be done directly on this data in AWS Athena Console\n",
    "\n",
    "The new 'DataSource' will show up in AWS and of course the SageWorks AWS Dashboard. Anyone can see the data, get information on it, use AWS® Athena to query it, and of course use it as part of their analysis pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b781d74",
   "metadata": {},
   "source": [
    "<div style=\"float: right; padding: 20px\"><img src=\"images/athena_query_aqsol.png\" width=600px\"></div>\n",
    "\n",
    "# Visibility and Easy to Use AWS Athena Queries\n",
    "Since SageWorks manages a broad range of AWS Services it means that you get visibility into exactly what data you have in AWS. It also means nice perks like hitting the 'Query' link in the Dashboard Web Interface and getting a direct Athena console on your dataset. With AWS Athena you can use typical SQL statements to inspect and investigate your data.\n",
    "    \n",
    "**But that's not all!**\n",
    "    \n",
    "SageWorks also provides API to directly query DataSources and FeatureSets right from the API, so lets do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sageworks.artifacts.data_sources.data_source import DataSource\n",
    "data_source = DataSource('wine_data')\n",
    "data_source.query('SELECT * from wine_data limit 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe38834",
   "metadata": {},
   "source": [
    "# The AWS ML Pipeline Awaits\n",
    "Okay, so in a few lines of code we created a 'DataSource' (which is simply a set of orchestrated AWS Services) but now we'll go through the construction of the rest of our Machine Learning pipeline.\n",
    "\n",
    "<div style=\"padding: 20px\">\n",
    "<img width=\"1000\" alt=\"sageworks_pipeline\" src=\"https://github.com/SuperCowPowers/sageworks/assets/4806709/47cc5739-971c-48c3-9ef6-fd8370e3ec57\"></div>\n",
    "\n",
    "## ML Pipeline\n",
    "- DataSource **(done)**\n",
    "- FeatureSet\n",
    "- Model\n",
    "- Endpoint (serves models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4292590a",
   "metadata": {},
   "source": [
    "# Create a FeatureSet\n",
    "**Note:** Normally this is where you'd do a deep dive on the data/features, look at data quality metrics, redudant features and engineer new features. For the purposes of this notebook we're simply going to take the features given to us in the AQSolDB data from the Harvard Dataverse, those features are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37674152",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source.column_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d1309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note to self: Perhaps lets trim down the imports :)\n",
    "from sageworks.transforms.data_to_features.light.data_to_features_light import DataToFeaturesLight\n",
    "help(DataToFeaturesLight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b361add2",
   "metadata": {},
   "source": [
    "```\n",
    "Help on class DataToFeaturesLight in module sageworks.transforms.data_to_features.light.data_to_features_light:\n",
    "\n",
    "class DataToFeaturesLight(sageworks.transforms.transform.Transform)\n",
    " |  DataToFeaturesLight(data_uuid: str, feature_uuid: str)\n",
    " |  \n",
    " |  DataToFeaturesLight: Base Class for Light DataSource to FeatureSet using Pandas\n",
    " |  \n",
    " |  Common Usage:\n",
    " |      to_features = DataToFeaturesLight(data_uuid, feature_uuid)\n",
    " |      to_features.set_output_tags([\"abalone\", \"public\", \"whatever\"])\n",
    " |      to_features.transform(target, id_column=\"id\"/None, event_time_column=\"date\"/None)\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed96f8c",
   "metadata": {},
   "source": [
    "# Why does creating a FeatureSet take a long time?\n",
    "Great question, between row 'ingestion' and waiting for the offline store to finish populating itself it does take a **long time**. SageWorks is simply invoking the AWS Service APIs and those APIs are taking a while to do their thing.\n",
    "\n",
    "The good news is that SageWorks can monitor and query the status of the object and let you know when things are ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3bf3b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_to_features = DataToFeaturesLight('wine_data', 'wine_features')\n",
    "data_to_features.set_output_tags([\"wine\", \"classification\", \"uci\"])\n",
    "data_to_features.transform(target=\"target\")  # The target variable is called 'target' ;p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee31e7f",
   "metadata": {},
   "source": [
    "```\n",
    "Reading Data Catalog Database: sagemaker_featurestore...\n",
    "Reading Data Catalog Database: sageworks...\n",
    "2023-10-01 13:21:30 (data_to_pandas.py:56) INFO Post-Transform: Checking Pandas DataFrame...\n",
    "2023-10-01 13:21:30 (data_to_pandas.py:57) INFO DataFrame Shape: (178, 14)\n",
    "Reading Feature Store Database...\n",
    "2023-10-01 13:21:34 (feature_set.py:45) INFO Could not find feature set wine_features within current visibility scope\n",
    "2023-10-01 13:21:34 (feature_set.py:74) INFO FeatureSet.exists() wine_features not found in AWS Metadata!\n",
    "2023-10-01 13:21:34 (pandas_to_features.py:221) INFO Prep the output_df (cat_convert, convert types, lowercase columns, add training column)...\n",
    "2023-10-01 13:21:34 (pandas_to_features.py:79) INFO Generating an id column before FeatureSet Creation...\n",
    "2023-10-01 13:21:34 (pandas_to_features.py:86) INFO Generating an event_time column before FeatureSet Creation...\n",
    "2023-10-01 13:21:34 (pandas_to_features.py:92) INFO Converting event_time to ISOFormat Date String before FeatureSet Creation...\n",
    "2023-10-01 13:21:35 (connector.py:62) INFO Retrieving SageWorks Metadata for Artifact: arn:aws:sagemaker:us-west-2:507740646243:feature-group/wine_feature_set...\n",
    "2023-10-01 13:21:35 (pandas_to_features.py:328) INFO FeatureSet being Created...\n",
    "2023-10-01 13:21:35 (connector.py:62) INFO Retrieving SageWorks Metadata for Artifact: arn:aws:sagemaker:us-west-2:507740646243:feature-group/test_feature_set...\n",
    "2023-10-01 13:21:35 (connector.py:62) INFO Retrieving SageWorks Metadata for Artifact: arn:aws:sagemaker:us-west-2:507740646243:feature-group/abalone_feature_set...\n",
    "2023-10-01 13:21:40 (pandas_to_features.py:328) INFO FeatureSet being Created...\n",
    "2023-10-01 13:22:22 (pandas_to_features.py:331) INFO FeatureSet wine_features successfully created\n",
    "2023-10-01 13:22:24 (pandas_to_features.py:304) INFO Added rows: 178\n",
    "2023-10-01 13:22:24 (pandas_to_features.py:305) INFO Failed rows: 0\n",
    "2023-10-01 13:22:24 (pandas_to_features.py:306) INFO Total rows to be ingested: 178\n",
    "2023-10-01 13:22:24 (pandas_to_features.py:310) INFO Post-Transform: Populating Offline Storage and make_ready()...\n",
    "Reading Feature Store Database...\n",
    "2023-10-01 13:22:26 (pandas_to_features.py:317) INFO Waiting for Feature Group Offline storage to be ready...\n",
    "2023-10-01 13:22:26 (pandas_to_features.py:318) INFO Note: This will often take 10-20 minutes...go have coffee or lunch :)\n",
    "2023-10-01 13:22:31 (pandas_to_features.py:338) INFO Waiting for AWS Feature Group wine_features Offline Storage (0 rows)...\n",
    "2023-10-01 13:29:58 (pandas_to_features.py:342) INFO Success: Reached Expected Rows (178 rows)...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b88130",
   "metadata": {},
   "source": [
    "# New FeatureSet shows up in Dashboard\n",
    "Now we see our new feature set automatically pop up in our dashboard. FeatureSet creation involves the most complex set of AWS Services:\n",
    "- New Entry in AWS Feature Store\n",
    "- Specific Type and Field Requirements are handled\n",
    "- Plus all the AWS Services associated with DataSources (see above)\n",
    "\n",
    "The new 'FeatureSet' will show up in AWS and of course the SageWorks AWS Dashboard. Anyone can see the feature set, get information on it, use AWS® Athena to query it, and of course use it as part of their analysis pipelines.\n",
    "\n",
    "<div style=\"padding: 20px\"><img src=\"images/dashboard_aqsol_features.png\" width=1000px\"></div>\n",
    "    \n",
    "**Important:** All inputs are stored to track provenance on your data as it goes through the pipeline. We can see the last field in the FeatureSet shows the input DataSource."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3943e7c0",
   "metadata": {},
   "source": [
    "# Publishing our Model\n",
    "**Note:** Normally this is where you'd do a deep dive on the feature set. For the purposes of this notebook we're simply going to take the features given to us and make a reference model that can track our baseline model performance for other to improve upon. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010006a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sageworks.transforms.features_to_model.features_to_model import FeaturesToModel\n",
    "help(FeaturesToModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b97adcd",
   "metadata": {},
   "source": [
    "```\n",
    "class FeaturesToModel(sageworks.transforms.transform.Transform)\n",
    " |  FeaturesToModel(feature_uuid: str, model_uuid: str)\n",
    " |  \n",
    " |  FeaturesToModel: Train/Create a Model from a FeatureSet\n",
    " |  \n",
    " |  Common Usage:\n",
    " |      to_model = FeaturesToModel(feature_uuid, model_uuid)\n",
    " |      to_model.set_output_tags([\"abalone\", \"public\", \"whatever\"])\n",
    " |      to_model.transform(target=\"class_number_of_rings\", description=\"Abalone Regression Model\".\n",
    " |                         input_feature_list=<features>, model_type=\"regressor/classifier\",\n",
    " |                         delete_existing=True/False)\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60276ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute our feature list (or have the Class guess it)\n",
    "features = data_source.column_names()\n",
    "features.remove(\"target\")\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_model = FeaturesToModel('wine_features', 'wine-classification')\n",
    "to_model.set_output_tags([\"wine\", \"classification\", \"reference\"])\n",
    "to_model.transform(target=\"target\",  description=\"Wine Classification Model\",\n",
    "                   feature_list=features, model_type='classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069bd05d",
   "metadata": {},
   "source": [
    "```\n",
    "INFO Created new training data s3://sandbox-sageworks-artifacts/feature-sets/wine_features/datasets/all_2023-10-01_19:44:57/7fa767fc-e461-4828-9d77-57ecd6f369ed.csv...\n",
    "INFO:sageworks.transforms.transform:Created new training data s3://sandbox-sageworks-artifacts/feature-sets/wine_features/datasets/all_2023-10-01_19:44:57/7fa767fc-e461-4828-9d77-57ecd6f369ed.csv...\n",
    "Using provided s3_resource\n",
    "INFO:sagemaker:Creating training-job with name: sagemaker-scikit-learn-2023-10-01-19-45-03-876\n",
    "2023-10-01 19:45:05 Starting - Starting the training job...\n",
    "2023-10-01 19:45:20 Starting - Preparing the instances for training......\n",
    "2023-10-01 19:46:16 Downloading - Downloading input data...\n",
    "2023-10-01 19:46:46 Training - Downloading the training image...\n",
    "2023-10-01 19:47:22 Training - Training image download completed. Training in progress.\n",
    "\n",
    "{'Class_1': 0, 'Class_2': 1, 'Class_3': 2}\n",
    "  wine_class  precision    recall    fscore  support\n",
    "0    Class_1   1.000000  0.888889  0.941176       18\n",
    "1    Class_2   0.857143  1.000000  0.923077       12\n",
    "2    Class_3   1.000000  1.000000  1.000000        9\n",
    "2023-10-01 23:59:26,689 sagemaker-containers INFO     Reporting training SUCCESS\n",
    "2023-10-01 19:47:37,071 sagemaker-containers INFO     Reporting training SUCCESS\n",
    "\n",
    "2023-10-01 19:47:53 Uploading - Uploading generated training model\n",
    "2023-10-01 19:47:53 Completed - Training job completed\n",
    "Training seconds: 96\n",
    "Billable seconds: 96\n",
    "2023-10-01 13:48:30 (features_to_model.py:142) INFO Creating new model wine-classification...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c9381",
   "metadata": {},
   "source": [
    "# Deploying an AWS Endpoint\n",
    "Okay now that are model has been published we can deploy an AWS Endpoint to serve inference requests for that model. Deploying an Endpoint allows a large set of servies/APIs to use our model in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a362f172",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sageworks.transforms.model_to_endpoint.model_to_endpoint import ModelToEndpoint\n",
    "to_endpoint = ModelToEndpoint(\"wine-classification\", \"wine-classification-end\")\n",
    "to_endpoint.set_output_tags([\"wine\", \"classification\"])\n",
    "to_endpoint.transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04024783",
   "metadata": {},
   "source": [
    "# Model Inference from the Endpoint\n",
    "AWS Endpoints will bundle up a model as a service that responds to HTTP requests. The typical way to use an endpoint is to send a POST request with your features in CSV format. SageWorks provides a nice DataFrame based interface that takes care of many details for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sageworks.artifacts.endpoints.endpoint import Endpoint\n",
    "help(Endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf683f6",
   "metadata": {},
   "source": [
    "```\n",
    "class Endpoint(sageworks.artifacts.artifact.Artifact)\n",
    " |  Endpoint(endpoint_uuid)\n",
    " |  \n",
    " |  Endpoint: SageWorks Endpoint Class\n",
    " |  \n",
    " |  Common Usage:\n",
    " |      my_endpoint = Endpoint(endpoint_uuid)\n",
    " |      prediction_df = my_endpoint.predict(test_df)\n",
    " |      metrics = my_endpoint.regression_metrics(target_column, prediction_df)\n",
    " |      for metric, value in metrics.items():\n",
    " |          print(f\"{metric}: {value:0.3f}\")\n",
    " |  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289d3380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Endpoint\n",
    "my_endpoint = Endpoint('wine-classification-end')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1cdebe",
   "metadata": {},
   "source": [
    "# Model Provenance is locked into SageWorks\n",
    "We can now look at the model, see what FeatureSet was used to train it and even better see exactly which ROWS in that training set where used to create the model. We can make a query that returns the ROWS that were not used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a12b00ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Feature Store Database...\n",
      "Reading Data Catalog Database: sageworks...\n",
      "2023-10-02 09:08:17 (feature_set.py:64) INFO FeatureSet Initialized: wine_features\n",
      "Reading Data Catalog Database: sagemaker_featurestore...\n",
      "2023-10-02 09:08:18 (connector.py:62) INFO Retrieving SageWorks Metadata for Artifact: arn:aws:sagemaker:us-west-2:507740646243:feature-group/wine_features...\n",
      "2023-10-02 09:08:18 (connector.py:62) INFO Retrieving SageWorks Metadata for Artifact: arn:aws:sagemaker:us-west-2:507740646243:feature-group/wine_feature_set...\n",
      "2023-10-02 09:08:18 (connector.py:62) INFO Retrieving SageWorks Metadata for Artifact: arn:aws:sagemaker:us-west-2:507740646243:feature-group/test_feature_set...\n",
      "2023-10-02 09:08:18 (connector.py:62) INFO Retrieving SageWorks Metadata for Artifact: arn:aws:sagemaker:us-west-2:507740646243:feature-group/abalone_feature_set...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>write_time</th>\n",
       "      <th>api_invocation_time</th>\n",
       "      <th>is_deleted</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280_od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>wine_class</th>\n",
       "      <th>id</th>\n",
       "      <th>event_time</th>\n",
       "      <th>training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-01 23:18:14.584000+00:00</td>\n",
       "      <td>2023-10-01 23:12:04+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>13.28</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.84</td>\n",
       "      <td>15.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.36</td>\n",
       "      <td>4.60</td>\n",
       "      <td>1.09</td>\n",
       "      <td>2.78</td>\n",
       "      <td>880.0</td>\n",
       "      <td>Class_1</td>\n",
       "      <td>36</td>\n",
       "      <td>2023-10-01T23:11:41.953Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-01 23:18:15.750000+00:00</td>\n",
       "      <td>2023-10-01 23:12:04+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>12.33</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.28</td>\n",
       "      <td>16.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.41</td>\n",
       "      <td>3.27</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.67</td>\n",
       "      <td>680.0</td>\n",
       "      <td>Class_2</td>\n",
       "      <td>60</td>\n",
       "      <td>2023-10-01T23:11:41.953Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-01 23:18:15.750000+00:00</td>\n",
       "      <td>2023-10-01 23:12:04+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>12.25</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.20</td>\n",
       "      <td>18.5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.14</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.00</td>\n",
       "      <td>855.0</td>\n",
       "      <td>Class_3</td>\n",
       "      <td>144</td>\n",
       "      <td>2023-10-01T23:11:41.953Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-01 23:18:16.008000+00:00</td>\n",
       "      <td>2023-10-01 23:12:05+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>13.30</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>17.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>Class_1</td>\n",
       "      <td>27</td>\n",
       "      <td>2023-10-01T23:11:41.953Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-01 23:18:15.727000+00:00</td>\n",
       "      <td>2023-10-01 23:12:05+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>14.22</td>\n",
       "      <td>3.99</td>\n",
       "      <td>2.51</td>\n",
       "      <td>13.2</td>\n",
       "      <td>128.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.08</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.53</td>\n",
       "      <td>760.0</td>\n",
       "      <td>Class_1</td>\n",
       "      <td>39</td>\n",
       "      <td>2023-10-01T23:11:41.953Z</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        write_time       api_invocation_time  is_deleted  \\\n",
       "0 2023-10-01 23:18:14.584000+00:00 2023-10-01 23:12:04+00:00       False   \n",
       "1 2023-10-01 23:18:15.750000+00:00 2023-10-01 23:12:04+00:00       False   \n",
       "2 2023-10-01 23:18:15.750000+00:00 2023-10-01 23:12:04+00:00       False   \n",
       "3 2023-10-01 23:18:16.008000+00:00 2023-10-01 23:12:05+00:00       False   \n",
       "4 2023-10-01 23:18:15.727000+00:00 2023-10-01 23:12:05+00:00       False   \n",
       "\n",
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    13.28        1.64  2.84               15.5      110.0           2.60   \n",
       "1    12.33        1.10  2.28               16.0      101.0           2.05   \n",
       "2    12.25        3.88  2.20               18.5      112.0           1.38   \n",
       "3    13.30        1.72  2.14               17.0       94.0           2.40   \n",
       "4    14.22        3.99  2.51               13.2      128.0           3.00   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        2.68                  0.34             1.36             4.60  1.09   \n",
       "1        1.09                  0.63             0.41             3.27  1.25   \n",
       "2        0.78                  0.29             1.14             8.21  0.65   \n",
       "3        2.19                  0.27             1.35             3.95  1.02   \n",
       "4        3.04                  0.20             2.08             5.10  0.89   \n",
       "\n",
       "   od280_od315_of_diluted_wines  proline wine_class   id  \\\n",
       "0                          2.78    880.0    Class_1   36   \n",
       "1                          1.67    680.0    Class_2   60   \n",
       "2                          2.00    855.0    Class_3  144   \n",
       "3                          2.77   1285.0    Class_1   27   \n",
       "4                          3.53    760.0    Class_1   39   \n",
       "\n",
       "                 event_time  training  \n",
       "0  2023-10-01T23:11:41.953Z         0  \n",
       "1  2023-10-01T23:11:41.953Z         0  \n",
       "2  2023-10-01T23:11:41.953Z         0  \n",
       "3  2023-10-01T23:11:41.953Z         0  \n",
       "4  2023-10-01T23:11:41.953Z         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sageworks.artifacts.feature_sets.feature_set import FeatureSet\n",
    "fs = FeatureSet('wine_features')\n",
    "table = fs.get_data_source().uuid\n",
    "test_df = fs.query(f\"select * from {table} where training=0\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed6c088a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "  wine_class  precision    recall    fscore  support\n",
      "0    Class_1   1.000000  0.888889  0.941176       18\n",
      "1    Class_2   0.857143  1.000000  0.923077       12\n",
      "2    Class_3   1.000000  1.000000  1.000000        9\n"
     ]
    }
   ],
   "source": [
    "# Okay now use the SageWorks Endpoint to make prediction on TEST data\n",
    "prediction_df = my_endpoint.predict(test_df)\n",
    "metrics = my_endpoint.classification_metrics(\"wine_class\", prediction_df)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a20529",
   "metadata": {},
   "source": [
    "# Follow Up on Predictions\n",
    "Looking at the prediction plot above we can see that many predictions were close to the actual value but about 10 of the predictions were WAY off. So at this point we'd use SageWorks to investigate those predictions, map them back to our FeatureSet and DataSource and see if there were irregularities in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2358b668",
   "metadata": {},
   "source": [
    "# Wrap up: Building an AWS<sup>®</sup> ML Pipeline with SageWorks\n",
    "\n",
    "<div style=\"float: right; padding: 20px\"><img width=\"450\" src=\"https://user-images.githubusercontent.com/4806709/266844238-df2f1b90-9e6f-4dbb-9490-ad75545e630f.png\"></div>\n",
    "\n",
    "\n",
    "\n",
    "This notebook used the SageWorks Science Toolkit to quickly build an AWS® Machine Learning Pipeline with the AQSolDB public dataset. We built a full AWS Machine Learning Pipeline from start to finish. \n",
    "\n",
    "SageWorks made it easy:\n",
    "- Visibility into AWS services for every step of the process.\n",
    "- Managed the complexity of organizing the data and populating the AWS services.\n",
    "- Provided an easy to use API to perform Transformations and inspect Artifacts.\n",
    "\n",
    "Using SageWorks will minimizize the time and manpower needed to incorporate AWS ML into your organization. If your company would like to be a SageWorks Alpha Tester, contact us at [sageworks@supercowpowers.com](mailto:sageworks@supercowpowers.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5ac2c7",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31162c1",
   "metadata": {},
   "source": [
    "# Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b6c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting defaults\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-deep')\n",
    "#plt.style.use('seaborn-dark')\n",
    "plt.rcParams['font.size'] = 12.0\n",
    "plt.rcParams['figure.figsize'] = 14.0, 7.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
