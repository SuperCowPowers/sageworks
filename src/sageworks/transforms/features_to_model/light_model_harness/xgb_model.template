# Imports for XGB Model
import xgboost as xgb

# Model Performance Scores
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, precision_recall_fscore_support

# Scikit Learn Imports
from sklearn.model_selection import train_test_split

from io import StringIO
import json
import argparse
import joblib
import os
import pandas as pd


if __name__ == '__main__':

    # Harness Template Parameters
    target = '{{target}}'
    feature_list = {{feature_list}}
    model_type = '{{model_type}}'
    validation_split = 0.2

    # Sagemaker specific arguments. Defaults are set in the environment variables.
    parser = argparse.ArgumentParser()
    parser.add_argument('--output-data-dir', type=str, default=os.environ['SM_OUTPUT_DATA_DIR'])
    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])
    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAIN'])
    args = parser.parse_args()

    # Read the training data into DataFrames
    training_files = [os.path.join(args.train, file) for file in os.listdir(args.train) if file.endswith('.csv')]
    print(f'Training Files: {training_files}')

    # Combine files and read them all into a single pandas dataframe
    all_df = pd.concat([pd.read_csv(file, engine="python") for file in training_files])

    # Features/Target output
    print(f"Target: {target}")
    print(f"Features: {str(feature_list)}")

    # Does the dataframe have a training column?
    if 'training' in all_df.columns:
        print("Found training column, splitting data based on training column")
        df_train = all_df[all_df['training'] == 1]
        df_val = all_df[all_df['training'] == 0]
    else:
        # Just do a random training Split
        print("No training column found, splitting data with random state=42")
        df_train, df_val = train_test_split(all_df, test_size=validation_split, random_state=42)
    print(f'FIT/TRAIN: {df_train.shape}')
    print(f'VALIDATiON: {df_val.shape}')

    # Now spin up our XGB Model
    if model_type == 'classifier':
        xgb_model = xgb.XGBClassifier()
    else:
        xgb_model = xgb.XGBRegressor()

    # Grab our Features, Target and Train the Model
    y = df_train[target]
    X = df_train[feature_list]
    xgb_model.fit(X, y)

    # Make Predictions on the Validation Set
    preds = xgb_model.predict(df_val[feature_list])

    # Report Performance Metrics
    if model_type == 'classifier':
        # Note: Using labels here might seem extraneous, but it ensures order of the output
        scores = precision_recall_fscore_support(df_val[target], preds, average=None, labels=[0, 1, 2])

        # Put the scores into a dataframe
        scores_T = list(map(list, zip(*scores)))
        score_df = pd.DataFrame({'level': ['low', 'medium', 'high'], 'precision': scores[0],
                                 'recall': scores[1], 'fscore': scores[2], 'support': scores[3]})
        print(score_df)
    else:
        rms = mean_squared_error(df_val[target], preds, squared=False)
        mae = mean_absolute_error(df_val[target], preds)
        r2 = r2_score(df_val[target], preds)
        print(f'RMSE: {rms:.3f}')
        print(f'MAE: {mae:.3f}')
        print(f'R2 Score: {r2:.3f}')

    # Now save the model to the standard place/name
    joblib.dump(xgb_model, os.path.join(args.model_dir, "xgb_model.joblib"))

    # Also save the features (this will validate input during predictions)
    with open(os.path.join(args.model_dir, "feature_columns.json"), "w") as fp:
        json.dump(feature_list, fp)


def model_fn(model_dir):
    """Deserialized and return fitted model"""
    clf = joblib.load(os.path.join(model_dir, "xgb_model.joblib"))
    return clf


def input_fn(input_data, content_type):
    """We only take CSV Input"""
    if content_type == "text/csv":
        # Read the input buffer as a CSV file.
        input_df = pd.read_csv(StringIO(input_data))
        return input_df
    else:
        raise ValueError("{} not supported by script!".format(content_type))


def output_fn(output_df, accept):
    """We only give CSV Output"""
    if accept == "text/csv":
        csv_buffer = StringIO()
        output_df.to_csv(csv_buffer, index=False)
        return csv_buffer.getvalue()
    else:
        raise RuntimeError("{} accept type is not supported by this script.".format(accept))


def predict_fn(df, model):
    """Make Predictions with our XGB Model"""

    # Grab our feature columns (from training)
    model_dir = os.environ['SM_MODEL_DIR']
    with open(os.path.join(model_dir, "feature_columns.json")) as fp:
        features = json.load(fp)
    print(f"Features: {features}")

    # Predict the features against our XGB Model
    predictions = model.predict(df[features])
    df['prediction'] = predictions

    # Does our model have a 'predict_proba' method? If so add that to the DataFrame as well
    if getattr(model, 'predict_proba', None):
        pred_proba = model.predict_proba(df[features])
        df['pred_proba'] = [json.dumps(p.tolist()) for p in pred_proba]  # We have to do this for CSV serialization

    # All done, return the DataFrame
    return df
